# 大模型训练基础

## 基础理论

### 神经网络
点到线到点，而神经网络可以理解成点线的网络图，可以把点跟线理解为一些数字，而训练就是类似训练点到线应该是什么数字，以概率来输出

### 训练流程
- 准备数据
- 把数据变成数字
- 搭建一个简单的神经网络
- 训练神经网络
- 把神经网络换成transformer
- 优化训练流程

### 安装虚拟环境
- mac 环境
打开终端导航到项目目录：cd path/to/your/project
创建虚拟环境：python3 -m venv mygpt
激活虚拟环境：source mygpt/bin/activate
退出虚拟环境：deactivate

- windows
打开命令提示符 CMD 或 PowerShell
导航到您的项目目录： cd path\to\your\project
创建虚拟环境：python -m venv mygpt
激活虚拟环境：
  CMD中： mygpt\Scripts\activate
  在PowerShell中：mygpt\Scripts\Activate.ps1

- 安装python库
  - 下载课程资料包里的requirment.txt,放到项目目录下(比如demo项目目录，mygpt是虚拟环境，requirment.txt就是放到demo目录下)，运行一下代码。ls 能看到mygpt文件夹和requirment.txt文件
  - 会帮忙安装相关依赖库，pytorch库等
```shell
  pip install -r requirment.txt
```

## 分词理论
人工智能是如何学习我们的文字的

### 人工智能处理文字的基本步骤
- 将文本转换为数字表示
- 利用这些数字表示进行计算和分析

#### 文本到数字的转换
- 分词 Tokenization：将文本分割成更小的单位 称为token
- 向量化 Vectorization： 将每个token转换为数字向量，这些向量通常被称为嵌入向量 Embedding Vectors

#### 分词定义 Tokenization
定义：将文本分割成最小的语义单元，这些单元称为token，介于字母和词之间的单位

示例：
  - ‘我喜欢吃’ -> ‘我’ ‘喜欢’ ‘吃’
  - ’我喜欢吃‘ -> ‘我’ ‘喜’ ‘欢’ ‘吃’
> 我们暂时用最简单的分词方法：每一个字符作为一个token，用数字表示
> 如‘我’->[0],'喜'->[1],'欢'->[2],'吃'->[3]

- 编码 ：上述的过程叫做encode
- vocab_size 一个编码方式里所有的分词数量

#### 编码和解码
- 编码：把分词编码成数字表示
- 解码：把数字表示解码为文字
 
#### 整体过程
- 编码：文字经过分词变为数字
- 神经网络：数字交由神经网络复杂运算后输出数字
- 解码：神经网络输出的数字交由解码器解码输出文字

## 世界主流分词方法
### Pytorch
- 便捷的神经网络训练框架
  1. 让初学者能够专注于理解和实现模型结构，不必过多关注底层细节
  2. 简化的模型定义、自动处理反向传播、高级优化器、内置损失函数、数据加载和预处理、GPU加速

### 主流分词方法
现实中以BPE算法为主
- Google/Meta： SentencePiece
- OpenAi：tiktoken
- 分词表大小 vocab_size
  - 课程：65个
  - ChatGpt：100277个
  - 分词表越小，data即torch.tensor则越大，分词表越大，data即torch.tensor则越小

## 嵌入式向量Embedding vector
### 向量化
从文字到数字的转化
- 向量：一组有序数字的集合，例如：[0.1,0.8]或[0.2，0.7，0.5，0.3]
- 向量化：代表着把一个分词，变成一组数字的过程
  - 使神经网络能够处理文字信息
  - 捕捉词语之间的语义关系
  - 神经网络擅长处理向量跟向量之间的关系
- 每一个分词所对应的这组有序数字的组合，叫做嵌入式向量embedding vector
  - "猫"->[0.1,0.8]
  - "汽车"->[0.9,0.1]

### 嵌入向量
- 嵌入向量里的每个维度代表不同的特征，维度越高，捕捉更丰富的语言特征
  - 2维：[体型，亲密程度] ｜ 4维：[体型，亲密程度，独立性，活跃度]
- 把数字想象成空间坐标，距离反映语义相似度：越近表示意思越相近
- 向量所包含的数字，做表可以进行数学运算，让人工智能了解组词之间的不同含义
  - 加减法：组合含义，如：“国王”-“男人”+“女人”="女王"
  - 乘法：计算向量之间的相似度，“猫”*“狗”>“猫”*“桌子”

### 分词到嵌入向量的完整过程
1. 读取文本  我养了三只猫和三只狗
2. 分词编码  我 养 了 三 只 猫 和 狗
            6  3 1  7 0  4  5  2
3. 嵌入向量  6->[0.1,0.8,0.4,0.3] 3->[0.9,0.1,0.8,0.9]
> text:我养了三只猫和三只狗 data:[6,3,1,7,0,4,5,2] vocab_size:8  n_embd:4 
4. n_embd可以简单理解为代表维度

#### 词汇嵌入
查找表，而不是矩阵计算
<img width="800" src="https://boonlean15.github.io/cheneyBlog/images/aiImg/1.png" alt="png"> 

> 嵌入向量训练的一部分，通过大量的训练不断优化向量，以更好地表示词语关系，现实中如ChatGPT，
> 会用12288个数字代表一个分词，也就是一个12288维度的向量

- vocab_size:100227
- n_embd:12288

## 训练原理 段落处理
当训练数据过大时，我们不会一次性丢给AI学习，会按比例分为训练集跟验证集

### 段落处理
- 把文章按照固定长度分段，再分批喂给神经网络并行学习
  - 段落处理：俗称上下文窗口，Context Window，简称T，模型的记忆范围
- 假设一个段落长度是8，我爱吃面条里的酱，[18,47,56,57,58,1,15,47,48]
  > 这个段落可以有多少示例给AI学习，会进行一个再拆分，让AI可以预测下一个文字，我们给到AI的文字长度也是不固定的
  - 我
  - 我爱
  - 我爱吃 等等...

### 批量处理
将多个批次的多个文本块堆叠成单个张量，输入AI进行处理
- 批次，batch，批处理影响训练速度和资源利用
- 批次间的独立性：每个批次彼此独立，有利于并行计算和灵活处理
> GPU非常擅长并行处理，一次多个段落一起学习，是AI比人类学习快的原因
