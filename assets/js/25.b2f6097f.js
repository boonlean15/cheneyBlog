(window.webpackJsonp=window.webpackJsonp||[]).push([[25],{336:function(t,s,a){"use strict";a.r(s);var n=a(27),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"神经网络"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#神经网络"}},[t._v("#")]),t._v(" 神经网络")]),t._v(" "),s("p",[t._v("点到线到点，而神经网络可以理解成点线的网络图，可以把点跟线理解为一些数字，而训练就是类似训练点到线应该是什么数字，以概率来输出")]),t._v(" "),s("h2",{attrs:{id:"pytorch搭建二元语言模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#pytorch搭建二元语言模型"}},[t._v("#")]),t._v(" PyTorch搭建二元语言模型")]),t._v(" "),s("ul",[s("li",[t._v("def init 初始化方法")]),t._v(" "),s("li",[t._v("def forward 前向传播")]),t._v(" "),s("li",[t._v("def generate 生成序列")])]),t._v(" "),s("h2",{attrs:{id:"def-forward前向传播"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#def-forward前向传播"}},[t._v("#")]),t._v(" def forward前向传播")]),t._v(" "),s("ul",[s("li",[t._v("logits得分\n"),s("blockquote",[s("p",[t._v("把token输入给模型后，模型经过计算，预测可能是哪个词的概率分布，vocab_size是多少，logits的预测就是多少，比如输入“我爱”，输出“你”的概率就会大一些")])])]),t._v(" "),s("li",[t._v("loss 损失：预期与实际的差异\n"),s("blockquote",[s("p",[t._v("logits与target的差异越小，loss越小。训练模型的目的，让模型预测的越来越准，loss越来越小")])])])]),t._v(" "),s("h3",{attrs:{id:"计算logits"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#计算logits"}},[t._v("#")]),t._v(" 计算logits")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("forward")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("idx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("targets"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        logits "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("token_embedding_table"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("idx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("ul",[s("li",[t._v("idx是输入的token即分词，维度是(B,T) B:批次 T:一组词的分词数，组长度，例如：8个词")]),t._v(" "),s("li",[t._v("经过嵌套层，把idx变成logits，logits的维度是(B,T,C)")]),t._v(" "),s("li",[t._v("C等于我们的词典大小，即vocab_size")]),t._v(" "),s("li",[t._v("随着神经网络的不断变化复杂，计算logits会不断加料，但C、vocab_size不变")])]),t._v(" "),s("h3",{attrs:{id:"计算loss"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#计算loss"}},[t._v("#")]),t._v(" 计算loss")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" targets "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果没有给定目标，直接返回logits")]),t._v("\n        loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# logits的形状，B:batch size,T:time steps,C:channel(vocab size)")]),t._v("\n        B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("T"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("C "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 调整logits形状，将B和T合并为一维")]),t._v("\n        logits "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("view"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("T"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("C"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 调整targets的形状，使其与logits匹配")]),t._v("\n        targets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" targets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("view"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("T"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用交叉熵损失函数计算loss")]),t._v("\n        loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cross_entropy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("targets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("loss \n")])])]),s("h2",{attrs:{id:"def-generate-生成"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#def-generate-生成"}},[t._v("#")]),t._v(" def generate 生成")]),t._v(" "),s("ul",[s("li",[t._v("根据forward()返回的logits来预测下一个token\n"),s("ul",[s("li",[t._v("首先去除最后一个token对应的logits")]),t._v(" "),s("li",[t._v("使用Softmax和Multinomial会根据logits预测出下一个token\n"),s("ul",[s("li",[t._v("Softmax将logits转换为概率分布")]),t._v(" "),s("li",[t._v("Multinomial用于根据这个分布采样下一个token")])])]),t._v(" "),s("li",[t._v("注意，目前的二元模型，最后一个词的logits仅与自己有关，目前只使用了一个嵌入层，和其他词汇无关")]),t._v(" "),s("li",[t._v("后面transofmer，我们会让最后一个token的logits和其他词，以及自己的位置有关系")])])])]),t._v(" "),s("p",[s("strong",[t._v("即使神经网络不断变换，generate架构不变")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 生成序列方法，根据当前上下文idx生成max_new_tokens个新token")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("generate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("idx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("max_new_tokens"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#循环生成max_new_tokens个新token")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _in "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("max_new_tokens"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#根据当前的idx预测下一个token的logits")]),t._v("\n            logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("idx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#取出最后一个时间步的logits")]),t._v("\n            logits "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#对logits应用softmax获取概率分布，从而预测下一个token")]),t._v("\n            probs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softmax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("dim"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            idx_next "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("multinomial"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("props"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("num_samples"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#将新生成的token索引添加到当前的idx序列中")]),t._v("\n            idx "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("idx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("idx_next"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("dim"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" idx\n")])])]),s("img",{attrs:{width:"800",src:"https://boonlean15.github.io/cheneyBlog/images/aiImg/2.png",alt:"png"}})])}),[],!1,null,null,null);s.default=e.exports}}]);