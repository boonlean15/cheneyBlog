(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{335:function(t,v,_){"use strict";_.r(v);var a=_(27),e=Object(a.a)({},(function(){var t=this,v=t._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[v("h1",{attrs:{id:"大模型训练基础"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大模型训练基础"}},[t._v("#")]),t._v(" 大模型训练基础")]),t._v(" "),v("h2",{attrs:{id:"基础理论"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础理论"}},[t._v("#")]),t._v(" 基础理论")]),t._v(" "),v("h3",{attrs:{id:"神经网络"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#神经网络"}},[t._v("#")]),t._v(" 神经网络")]),t._v(" "),v("p",[t._v("点到线到点，而神经网络可以理解成点线的网络图，可以把点跟线理解为一些数字，而训练就是类似训练点到线应该是什么数字，以概率来输出")]),t._v(" "),v("h3",{attrs:{id:"训练流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#训练流程"}},[t._v("#")]),t._v(" 训练流程")]),t._v(" "),v("ul",[v("li",[t._v("准备数据")]),t._v(" "),v("li",[t._v("把数据变成数字")]),t._v(" "),v("li",[t._v("搭建一个简单的神经网络")]),t._v(" "),v("li",[t._v("训练神经网络")]),t._v(" "),v("li",[t._v("把神经网络换成transformer")]),t._v(" "),v("li",[t._v("优化训练流程")])]),t._v(" "),v("h3",{attrs:{id:"安装虚拟环境"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#安装虚拟环境"}},[t._v("#")]),t._v(" 安装虚拟环境")]),t._v(" "),v("ul",[v("li",[v("p",[t._v("mac 环境\n打开终端导航到项目目录：cd path/to/your/project\n创建虚拟环境：python3 -m venv mygpt\n激活虚拟环境：source mygpt/bin/activate\n退出虚拟环境：deactivate")])]),t._v(" "),v("li",[v("p",[t._v("windows\n打开命令提示符 CMD 或 PowerShell\n导航到您的项目目录： cd path\\to\\your\\project\n创建虚拟环境：python -m venv mygpt\n激活虚拟环境：\nCMD中： mygpt\\Scripts\\activate\n在PowerShell中：mygpt\\Scripts\\Activate.ps1")])]),t._v(" "),v("li",[v("p",[t._v("安装python库")]),t._v(" "),v("ul",[v("li",[t._v("下载课程资料包里的requirment.txt,放到项目目录下(比如demo项目目录，mygpt是虚拟环境，requirment.txt就是放到demo目录下)，运行一下代码。ls 能看到mygpt文件夹和requirment.txt文件")]),t._v(" "),v("li",[t._v("会帮忙安装相关依赖库，pytorch库等")])])])]),t._v(" "),v("div",{staticClass:"language-shell extra-class"},[v("pre",{pre:!0,attrs:{class:"language-shell"}},[v("code",[t._v("  pip "),v("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-r")]),t._v(" requirment.txt\n")])])]),v("h2",{attrs:{id:"分词理论"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分词理论"}},[t._v("#")]),t._v(" 分词理论")]),t._v(" "),v("p",[t._v("人工智能是如何学习我们的文字的")]),t._v(" "),v("h3",{attrs:{id:"人工智能处理文字的基本步骤"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#人工智能处理文字的基本步骤"}},[t._v("#")]),t._v(" 人工智能处理文字的基本步骤")]),t._v(" "),v("ul",[v("li",[t._v("将文本转换为数字表示")]),t._v(" "),v("li",[t._v("利用这些数字表示进行计算和分析")])]),t._v(" "),v("h4",{attrs:{id:"文本到数字的转换"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#文本到数字的转换"}},[t._v("#")]),t._v(" 文本到数字的转换")]),t._v(" "),v("ul",[v("li",[t._v("分词 Tokenization：将文本分割成更小的单位 称为token")]),t._v(" "),v("li",[t._v("向量化 Vectorization： 将每个token转换为数字向量，这些向量通常被称为嵌入向量 Embedding Vectors")])]),t._v(" "),v("h4",{attrs:{id:"分词定义-tokenization"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分词定义-tokenization"}},[t._v("#")]),t._v(" 分词定义 Tokenization")]),t._v(" "),v("p",[t._v("定义：将文本分割成最小的语义单元，这些单元称为token，介于字母和词之间的单位")]),t._v(" "),v("p",[t._v("示例：")]),t._v(" "),v("ul",[v("li",[t._v("‘我喜欢吃’ -> ‘我’ ‘喜欢’ ‘吃’")]),t._v(" "),v("li",[t._v("’我喜欢吃‘ -> ‘我’ ‘喜’ ‘欢’ ‘吃’")])]),t._v(" "),v("blockquote",[v("p",[t._v("我们暂时用最简单的分词方法：每一个字符作为一个token，用数字表示\n如‘我’->[0],'喜'->[1],'欢'->[2],'吃'->[3]")])]),t._v(" "),v("ul",[v("li",[t._v("编码 ：上述的过程叫做encode")]),t._v(" "),v("li",[t._v("vocab_size 一个编码方式里所有的分词数量")])]),t._v(" "),v("h4",{attrs:{id:"编码和解码"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#编码和解码"}},[t._v("#")]),t._v(" 编码和解码")]),t._v(" "),v("ul",[v("li",[t._v("编码：把分词编码成数字表示")]),t._v(" "),v("li",[t._v("解码：把数字表示解码为文字")])]),t._v(" "),v("h4",{attrs:{id:"整体过程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#整体过程"}},[t._v("#")]),t._v(" 整体过程")]),t._v(" "),v("ul",[v("li",[t._v("编码：文字经过分词变为数字")]),t._v(" "),v("li",[t._v("神经网络：数字交由神经网络复杂运算后输出数字")]),t._v(" "),v("li",[t._v("解码：神经网络输出的数字交由解码器解码输出文字")])]),t._v(" "),v("h2",{attrs:{id:"世界主流分词方法"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#世界主流分词方法"}},[t._v("#")]),t._v(" 世界主流分词方法")]),t._v(" "),v("h3",{attrs:{id:"pytorch"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#pytorch"}},[t._v("#")]),t._v(" Pytorch")]),t._v(" "),v("ul",[v("li",[t._v("便捷的神经网络训练框架\n"),v("ol",[v("li",[t._v("让初学者能够专注于理解和实现模型结构，不必过多关注底层细节")]),t._v(" "),v("li",[t._v("简化的模型定义、自动处理反向传播、高级优化器、内置损失函数、数据加载和预处理、GPU加速")])])])]),t._v(" "),v("h3",{attrs:{id:"主流分词方法"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#主流分词方法"}},[t._v("#")]),t._v(" 主流分词方法")]),t._v(" "),v("p",[t._v("现实中以BPE算法为主")]),t._v(" "),v("ul",[v("li",[t._v("Google/Meta： SentencePiece")]),t._v(" "),v("li",[t._v("OpenAi：tiktoken")]),t._v(" "),v("li",[t._v("分词表大小 vocab_size\n"),v("ul",[v("li",[t._v("课程：65个")]),t._v(" "),v("li",[t._v("ChatGpt：100277个")]),t._v(" "),v("li",[t._v("分词表越小，data即torch.tensor则越大，分词表越大，data即torch.tensor则越小")])])])]),t._v(" "),v("h2",{attrs:{id:"嵌入式向量embedding-vector"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#嵌入式向量embedding-vector"}},[t._v("#")]),t._v(" 嵌入式向量Embedding vector")]),t._v(" "),v("h3",{attrs:{id:"向量化"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#向量化"}},[t._v("#")]),t._v(" 向量化")]),t._v(" "),v("p",[t._v("从文字到数字的转化")]),t._v(" "),v("ul",[v("li",[t._v("向量：一组有序数字的集合，例如：[0.1,0.8]或[0.2，0.7，0.5，0.3]")]),t._v(" "),v("li",[t._v("向量化：代表着把一个分词，变成一组数字的过程\n"),v("ul",[v("li",[t._v("使神经网络能够处理文字信息")]),t._v(" "),v("li",[t._v("捕捉词语之间的语义关系")]),t._v(" "),v("li",[t._v("神经网络擅长处理向量跟向量之间的关系")])])]),t._v(" "),v("li",[t._v("每一个分词所对应的这组有序数字的组合，叫做嵌入式向量embedding vector\n"),v("ul",[v("li",[t._v('"猫"->[0.1,0.8]')]),t._v(" "),v("li",[t._v('"汽车"->[0.9,0.1]')])])])]),t._v(" "),v("h3",{attrs:{id:"嵌入向量"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#嵌入向量"}},[t._v("#")]),t._v(" 嵌入向量")]),t._v(" "),v("ul",[v("li",[t._v("嵌入向量里的每个维度代表不同的特征，维度越高，捕捉更丰富的语言特征\n"),v("ul",[v("li",[t._v("2维：[体型，亲密程度] ｜ 4维：[体型，亲密程度，独立性，活跃度]")])])]),t._v(" "),v("li",[t._v("把数字想象成空间坐标，距离反映语义相似度：越近表示意思越相近")]),t._v(" "),v("li",[t._v("向量所包含的数字，做表可以进行数学运算，让人工智能了解组词之间的不同含义\n"),v("ul",[v("li",[t._v('加减法：组合含义，如：“国王”-“男人”+“女人”="女王"')]),t._v(" "),v("li",[t._v("乘法：计算向量之间的相似度，“猫”"),v("em",[t._v("“狗”>“猫”")]),t._v("“桌子”")])])])]),t._v(" "),v("h3",{attrs:{id:"分词到嵌入向量的完整过程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分词到嵌入向量的完整过程"}},[t._v("#")]),t._v(" 分词到嵌入向量的完整过程")]),t._v(" "),v("ol",[v("li",[t._v("读取文本  我养了三只猫和三只狗")]),t._v(" "),v("li",[t._v("分词编码  我 养 了 三 只 猫 和 狗\n6  3 1  7 0  4  5  2")]),t._v(" "),v("li",[t._v("嵌入向量  6->[0.1,0.8,0.4,0.3] 3->[0.9,0.1,0.8,0.9]")])]),t._v(" "),v("blockquote",[v("p",[t._v("text:我养了三只猫和三只狗 data:[6,3,1,7,0,4,5,2] vocab_size:8  n_embd:4")])]),t._v(" "),v("ol",{attrs:{start:"4"}},[v("li",[t._v("n_embd可以简单理解为代表维度")])]),t._v(" "),v("h4",{attrs:{id:"词汇嵌入"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#词汇嵌入"}},[t._v("#")]),t._v(" 词汇嵌入")]),t._v(" "),v("p",[t._v("查找表，而不是矩阵计算\n"),v("img",{attrs:{width:"800",src:"https://boonlean15.github.io/cheneyBlog/images/aiImg/1.png",alt:"png"}})]),t._v(" "),v("blockquote",[v("p",[t._v("嵌入向量训练的一部分，通过大量的训练不断优化向量，以更好地表示词语关系，现实中如ChatGPT，\n会用12288个数字代表一个分词，也就是一个12288维度的向量")])]),t._v(" "),v("ul",[v("li",[t._v("vocab_size:100227")]),t._v(" "),v("li",[t._v("n_embd:12288")])]),t._v(" "),v("h2",{attrs:{id:"训练原理-段落处理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#训练原理-段落处理"}},[t._v("#")]),t._v(" 训练原理 段落处理")]),t._v(" "),v("p",[t._v("当训练数据过大时，我们不会一次性丢给AI学习，会按比例分为训练集跟验证集")]),t._v(" "),v("h3",{attrs:{id:"段落处理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#段落处理"}},[t._v("#")]),t._v(" 段落处理")]),t._v(" "),v("ul",[v("li",[t._v("把文章按照固定长度分段，再分批喂给神经网络并行学习\n"),v("ul",[v("li",[t._v("段落处理：俗称上下文窗口，Context Window，简称T，模型的记忆范围")])])]),t._v(" "),v("li",[t._v("假设一个段落长度是8，我爱吃面条里的酱，[18,47,56,57,58,1,15,47,48]\n"),v("blockquote",[v("p",[t._v("这个段落可以有多少示例给AI学习，会进行一个再拆分，让AI可以预测下一个文字，我们给到AI的文字长度也是不固定的")])]),t._v(" "),v("ul",[v("li",[t._v("我")]),t._v(" "),v("li",[t._v("我爱")]),t._v(" "),v("li",[t._v("我爱吃 等等...")])])])]),t._v(" "),v("h3",{attrs:{id:"批量处理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#批量处理"}},[t._v("#")]),t._v(" 批量处理")]),t._v(" "),v("p",[t._v("将多个批次的多个文本块堆叠成单个张量，输入AI进行处理")]),t._v(" "),v("ul",[v("li",[t._v("批次，batch，批处理影响训练速度和资源利用")]),t._v(" "),v("li",[t._v("批次间的独立性：每个批次彼此独立，有利于并行计算和灵活处理")])]),t._v(" "),v("blockquote",[v("p",[t._v("GPU非常擅长并行处理，一次多个段落一起学习，是AI比人类学习快的原因")])])])}),[],!1,null,null,null);v.default=e.exports}}]);